{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_data(file_name: str, hypothesis_flag) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load file containg details of LCA and retain only useful columns.\n",
    "    Replace the column names with meaningful heads.\n",
    "    :param filename: The path to the LCA data file.\n",
    "    \"\"\"\n",
    "\n",
    "    col_required = ['STATUS', 'CASE_STATUS', 'LCA_CASE_EMPLOYER_NAME', 'EMPLOYER_NAME', 'TOTAL_WORKERS',\n",
    "                    'TOTAL_WORKER_POSITIONS',\n",
    "                    'LCA_CASE_WORKLOC1_STATE', 'VISA_CLASS', 'LCA_CASE_NUMBER', 'LCA_CASE_NAICS_CODE', 'NAICS_CODE',\n",
    "                    'TOTAL WORKERS', 'WORKSITE_STATE', 'WORKSITE_STATE_1', 'CASE_NUMBER', 'NAIC_CODE']\n",
    "\n",
    "    df = pd.read_csv(filepath_or_buffer=file_name, usecols=lambda x: x in col_required,\n",
    "                     dtype={'LCA_CASE_NAICS_CODE': 'str',\n",
    "                            'NAICS_CODE': 'str',\n",
    "                            'NAIC_CODE': 'str',\n",
    "                            },\n",
    "                     low_memory=False, encoding='ISO-8859-1')\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={'LCA_CASE_NUMBER': 'CASE_NUMBER', 'CASE_STATUS': 'STATUS', 'LCA_CASE_EMPLOYER_NAME': 'EMPLOYER_NAME',\n",
    "                 'TOTAL_WORKER_POSITIONS': 'TOTAL_WORKERS', 'LCA_CASE_WORKLOC1_STATE': 'WORKSITE_STATE',\n",
    "                 'LCA_CASE_NAICS_CODE': 'NAICS_CODE', 'WORKSITE_STATE_1': 'WORKSITE_STATE', 'NAIC_CODE': 'NAICS_CODE',\n",
    "                 'TOTAL WORKERS': 'TOTAL_WORKERS'})\n",
    "    if hypothesis_flag == False:\n",
    "            df['STATUS'] = df[\"STATUS\"].str.upper()\n",
    "            df = df[(df['STATUS'] == 'CERTIFIED') & (df['VISA_CLASS'] == 'H-1B')]\n",
    "            df['NAICS_CODE'] = df['NAICS_CODE'].str[:2]\n",
    "            return (df)\n",
    "    elif hypothesis_flag == True:\n",
    "            df['STATUS'] = df[\"STATUS\"].str.upper()            \n",
    "            df['NAICS_CODE'] = df['NAICS_CODE'].str[:2]\n",
    "            df = df[df['VISA_CLASS'] == 'H-1B']\n",
    "            return (df)\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_range(row):\n",
    "    if isinstance(row, list) and len(row) > 1:\n",
    "        return list(range(int(row[0]), int(row[1]) + 1))\n",
    "    elif isinstance(row, list):\n",
    "        return row[0]\n",
    "\n",
    "def read_sector_data (filename : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the NAICS data file, retaining only the most useful columns & rows.\n",
    "    Change the layout for a few rows to make the data inclusive of a codes.\n",
    "    :param filename: The path to the NAICS code data file.\n",
    " \n",
    "    \"\"\"\n",
    "    sector_df = pd.read_csv(filepath_or_buffer=filename,encoding='ISO-8859-1')\n",
    "    sector_df[\"Sector\"]=sector_df[\"Sector\"].str.split(\"-\")\n",
    "    sector_df['sector_range'] = sector_df[\"Sector\"].apply(sector_range)\n",
    "    sector_codes = sector_df['sector_range'].apply(pd.Series).reset_index().melt(id_vars='index').dropna()[['index', 'value']].set_index('index')\n",
    "    sector_codes_final = sector_codes.merge(sector_df['Name'], left_index=True, right_index=True, how='inner')\n",
    "    sector_codes_final = sector_codes_final.rename(columns={\"value\": \"Sector\"})\n",
    "    sector_codes_final['Sector']= sector_codes_final['Sector'].astype('int8')\n",
    "    return(sector_codes_final)\n",
    "\n",
    "def hypothesis_one_cal(year_df, sector_data_df, yy):\n",
    "    year_df =year_df.merge(sector_data_df, how='left', left_on='NAICS_CODE', right_on='Sector')\n",
    "    stats_df = year_df.groupby(['Name'])['TOTAL_WORKERS'].sum().astype('int32').reset_index(name=yy)\n",
    "    return( stats_df)\n",
    "\n",
    "def hypothesis_one(file_list):\n",
    "    sector_df = read_sector_data ('2017_NAICS_Structure_Summary_Table.csv')\n",
    "    sector_df['Sector'] = sector_df['Sector'].astype('str')\n",
    "    sector_name = sector_df.Name.unique().tolist()\n",
    "    plot_data_df = pd.DataFrame()\n",
    "    plot_data_df['Sectors']= sector_name\n",
    "    for file in file_list:\n",
    "        file_name = \"data_H1B/\" + file\n",
    "        hypothesis_flag = False\n",
    "        year_data = read_data (file_name, hypothesis_flag)\n",
    "        year = '20' + file[7:9]\n",
    "        stats = hypothesis_one_cal(year_data,sector_df,year)\n",
    "        plot_data_df = plot_data_df.merge(stats, how='left', left_on='Sectors', right_on='Name')\n",
    "        del plot_data_df['Name']\n",
    "    return(plot_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hypothesis_two(directory):\n",
    "    country = ['China - mainland', 'China - Taiwan','India', 'Korea, South', 'Mexico','Brazil', 'Australia', 'Russia','Great Britain and Northern Ireland',\n",
    "                'Germany','France', 'Philippines']\n",
    "    sd= pd.DataFrame({\"Nationality\": country})\n",
    "    for file in directory:\n",
    "        col_name = 'Fiscal Year 20' + file[2:4]\n",
    "        file_name = \"data_Country/\" + file\n",
    "        df = pd.read_csv(filepath_or_buffer=file_name,thousands=',', dtype= {'H-1B':'float'})\n",
    "        df=df.rename(columns={'Unnamed: 0': 'Visa_Country', col_name: 'Visa_Country'})\n",
    "        df= df[['Visa_Country','H-1B']]\n",
    "        df= df.rename(columns ={'H-1B': col_name})\n",
    "        sd =sd.merge(df, how='left',  left_on= 'Nationality', right_on='Visa_Country')\n",
    "        del sd['Visa_Country']\n",
    "    return (sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_hypothesis_three(file_list):\n",
    "    company_df = pd.read_csv(\"companylist.csv\", dtype={'MarketCap': 'float64'})\n",
    "    final_df = pd.DataFrame()\n",
    "    list_of_df = []\n",
    "    for file in file_list:\n",
    "        file_name = \"data_H1B/\" + file\n",
    "        hypothesis_flag = True\n",
    "        year_data = read_data (file_name, hypothesis_flag)\n",
    "        year = '20' + file[7:9]\n",
    "        company_df['name_lower'] = company_df['Name'].str.lower()\n",
    "        year_data['EMPLOYER_NAME_lower'] = year_data['EMPLOYER_NAME'].str.lower()\n",
    "        companylist_merged_df = year_data.merge(company_df, left_on='EMPLOYER_NAME_lower', right_on='name_lower')\n",
    "        companylist_merged_df_certified = pd.DataFrame()\n",
    "        companylist_merged_df_total = pd.DataFrame()\n",
    "        companylist_merged_df_total = companylist_merged_df.groupby(['EMPLOYER_NAME','MarketCap'])['TOTAL_WORKERS'].sum().reset_index(name=\"TOTAL_WORKERS_OVERALL\")\n",
    "        companylist_merged_df_certified = companylist_merged_df[companylist_merged_df['STATUS'] == 'CERTIFIED'].groupby(['EMPLOYER_NAME','MarketCap'])['TOTAL_WORKERS'].sum().reset_index(name=\"CERTIFIED_TOTAL_WORKERS\")\n",
    "        companylist_merged_df_certified['year'] = year\n",
    "        companylist_merged_df_total['year'] = year\n",
    "        new_data = companylist_merged_df_certified.merge(companylist_merged_df_total, on='EMPLOYER_NAME')  \n",
    "        new_data['MarketCap_x'].astype('float64')\n",
    "        new_data['Rate'] = (new_data['CERTIFIED_TOTAL_WORKERS'] / new_data['TOTAL_WORKERS_OVERALL'])*100\n",
    "        new_data = new_data[['EMPLOYER_NAME', 'Rate', 'MarketCap_x','year_x']]\n",
    "        #print(new_data.sort_values(by='Rate', ascending=False))\n",
    "        list_of_df.append(new_data)\n",
    "    final_df = pd.concat(list_of_df,ignore_index=True)\n",
    "    print(final_df)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        EMPLOYER_NAME        Rate   MarketCap_x year_x\n",
      "0                       ABIOMED, INC.  100.000000  1.620249e+10   2011\n",
      "1                ACCURAY INCORPORATED  100.000000  4.481857e+08   2011\n",
      "2                 ACI WORLDWIDE, INC.   90.909091  3.577972e+09   2011\n",
      "3           ACORDA THERAPEUTICS, INC.   75.000000  6.472690e+08   2011\n",
      "4     ADESTO TECHNOLOGIES CORPORATION  100.000000  1.654199e+08   2011\n",
      "...                               ...         ...           ...    ...\n",
      "4693                        eBay Inc.   98.969072  3.389632e+10   2020\n",
      "4694                eGain Corporation  100.000000  3.239460e+08   2020\n",
      "4695       iRhythm Technologies, Inc.  100.000000  2.218932e+09   2020\n",
      "4696               iRobot Corporation  100.000000  3.336530e+09   2020\n",
      "4697                  j2 Global, Inc.  100.000000  4.162894e+09   2020\n",
      "\n",
      "[4698 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = \"data_H1B/\"\n",
    "    directory = os.listdir(path)\n",
    "    #df = hypothesis_one(directory)\n",
    "    df_hypothesis_three(directory)    \n",
    "    #hypothesis_two(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}